{"AvgTrainReward":0.1027,"AvgEvalReward":260.3,"_runtime":0,"AvgLoss":0.119959,"_step":1999,"Epsilon":0.1,"Step":2e+07,"Episode":243.90243902439025,"_timestamp":1.7621654147009888e+09,"_wandb":{"runtime":0}}