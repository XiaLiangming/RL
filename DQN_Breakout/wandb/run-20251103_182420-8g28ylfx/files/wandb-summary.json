{"_runtime":0,"AvgTrainReward":0.1126,"Step":2e+07,"Episode":158.73015873015873,"_step":1999,"_wandb":{"runtime":0},"_timestamp":1.7621654628408926e+09,"Epsilon":0.1,"AvgLoss":0.128709,"AvgEvalReward":159.8}