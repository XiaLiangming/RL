{"Epsilon":0.1,"AvgEvalReward":260.3,"AvgTrainReward":0.1027,"_runtime":0,"Step":2e+07,"_timestamp":1.7618811582564974e+09,"Episode":243.90243902439025,"_wandb":{"runtime":0},"_step":1999,"AvgLoss":3.8387}